{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedc78f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bc327510584cf6bb9923716afefe90b",
     "grade": false,
     "grade_id": "cell-220cfc15877a15ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 4\n",
    "\n",
    "## Lecture 7 & 8 - Clustering & Probability Theory\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "* Learn how to **construct** and **train** K-means for **hard-clustering** task using `scikit-learn`. \n",
    "* Learn the importance of K-means initialization.\n",
    "* Learn about the properties of K-means clusters.\n",
    "* Learn how to use inertia and silhouette coefficient to choose the number of clusters k.\n",
    "* Learn how to construct new features using clustering, and to leverage those for more expressive (supervised) models.\n",
    "* Learn the basics of Bayesian probability theory\n",
    "* Learn how to train a naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c9fd6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7969938d8df5fb427f81025776f862ae",
     "grade": false,
     "grade_id": "cell-1d28f7b8df7f9ea5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Table of Contents\n",
    "1. [Clustering](#Clustering)\n",
    "2. [Bayes Classifier](#Bayes-Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119fb9a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dfba16acdfd8b0df56fc3318a9e6aa8",
     "grade": false,
     "grade_id": "cell-0c2dcf4cedc66b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# General Instructions\n",
    "- Jupyter notebook is supposed to be run cell by cell in order, please do not skip any code cell, this will cause some errors. Also running cells back and forth sometimes might also incur errors. If you feel you lost your track, you can click \"Kernel->Restart\" from the menu to restart the process.\n",
    "- Before submitting your assignment, ensure that it does not contain trivial errors by pressing the \"validate\" button at the top.\n",
    "- Your implementations are supposed to be added to the places where it reads \"YOUR CODE HERE\". Please also remove the \"raise NotImplementedError()\" line before submitting.\n",
    "- Please DO NOT change the metadata of any cell, cells for demo and instructions are not editable.\n",
    "- Please DO NOT change the order of solution cell and test cell, you will lost points if the order is changed.\n",
    "- You can copy lines of code from cells that are not editable, but please DO NOT copy and paste them as cells, this may incur validation error. \n",
    "- You can add extra cells or code to help double-check your solution, but please make sure that variables required by tasks are not overwritten, or just delete those extra cells before submitting.\n",
    "- Please DO NOT change file names in you submission, renamed files can not be recognized by the grading system.\n",
    "- Reading the documentation of Python libraries is always a good practice, all the Python libraries (Numpy, Pandas, Sklearn,etc.) we utilized in this course provide very well organized documentation for each method/class/function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc9b89",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7492717ebbc443a63f1ea2e012eadf23",
     "grade": false,
     "grade_id": "cell-684df6da27545715",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for this assignment\n",
    "from re import findall # regular expressions\n",
    "from time import time # library providing various time-related functions\n",
    "\n",
    "import numpy as np # library for numerical computations (vectors, matrices, tensors)\n",
    "import numpy.testing as np_testing # for tests\n",
    "import matplotlib.pyplot as plt # library providing tools for plotting data\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris # function providing iris dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans # library for K-Means clustering\n",
    "from sklearn import metrics # library providing score functions, performance metrics and pairwise metrics and distance computations\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix as calculate_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D # library for 3D axes object\n",
    "from seaborn import heatmap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3ff54",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10e52f5f733e95ac37128f2f22f89690",
     "grade": false,
     "grade_id": "cell-851f05f8fc7653db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Clustering\n",
    "\n",
    "Here we discuss about an unsupervised ML method [Clustering](https://en.wikipedia.org/wiki/Cluster_analysis), which does not require a supervisor to provide the label values for any datapoint. Clustering methods aim to decompose datapoints into a few subsets which we refer to as clusters. They learn a hypothesis for assigning each data point either to one cluster or several clusters with different degrees of belonging.\n",
    "\n",
    "Broadly speaking, clustering can be divided into two subgroups:\n",
    "\n",
    "- **Hard Clustering**: In hard clustering, each data point either belongs to a cluster completely or not. \n",
    "- **Soft Clustering**: In soft clustering, instead of putting each data point into a separate cluster, a probability or likelihood of that data point to be in those clusters is assigned. \n",
    "\n",
    "Clustering of unlabeled data can be performed with the module [`sklearn.cluster`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster). Each clustering algorithm comes in two variants: a class ([python class](https://docs.python.org/3/tutorial/classes.html)), that implements the `fit.()` method to learn the clusters on training data, and a function, that, given training data, returns an array of integer labels corresponding to the different clusters. For the class, the labels over the training data can be found in the `labels_` attribute. Here is the overview of [clustering methods](https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods).\n",
    "\n",
    "In this assignment, we will use **K-means** to solve a **hard-clustering** task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4691e5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ce1ec0dfdbaf507fed8fc1fab85bbf8",
     "grade": false,
     "grade_id": "cell-4762b48f56262c4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='A4.1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h2><b>Student task A4.1.</b> K-means for hard-clustering problem.</h2>\n",
    "\n",
    "Now, your task is to use **K-means** for a **hard-clustering** problem. \n",
    "    \n",
    "You can use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) to construct the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a88c00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ae4dd346a75bbed8c5b364363b26c4e",
     "grade": false,
     "grade_id": "cell-5b8331730324a5a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The **[KMeans](https://en.wikipedia.org/wiki/K-means_clustering)** algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.\n",
    "\n",
    "The k-means algorithm divides a set of $N$ samples $X = \\{x_1,x_2,...,x_n\\}$ into $K$ disjoint clusters $C_1,C_2,...,C_k$, each described by the mean $\\mu_j$ of the samples in the cluster $C_j$, for $j \\in \\{1,2,3,...,k\\}$ . The means are commonly called the cluster “centroids”; note that they are not, in general, points from $X$, although they live in the same space.\n",
    "\n",
    "The K-means algorithm aims to choose centroids that minimise the **inertia**, or **within-cluster sum-of-squares criterion**:\n",
    "$$\n",
    "\\mathop{min}\\limits_{\\mathbf{\\mu}}\n",
    "\\sum^{k}_{j=1}\n",
    "\\sum^{}_{x_i\\in C_j}\n",
    "\\| x_i - \\mu_j\\|^2\n",
    "$$\n",
    "\n",
    "Furthermore, since the total variance in the data is a constant, by minimizing the within-cluster (intra) variance we are also implicitly *maximizing* the between-cluster (inter) variance. As a result, K-means tries to find well separated spherical clusters with equal densities. More specifically, K-means can only produce convex clusters, which makes it less useful when the targeted/real clusters are strongly overlapping or entangled. And finally, whether or not there is actually any \"clustering/grouping\" we as humans might recognize or wish to find in the data, K-means **will** return us k cluster centroids, and those centroids will partition the input space in convex partitions using euclidean distance. It is solely on the analyst to interpret and validate the results using ingenuity and existing tools (goodness measures, visual inspection etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec0402",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e6c29359970caf7972471e9da8c26ee",
     "grade": false,
     "grade_id": "cell-d12c343a550b4be4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading Data\n",
    "\n",
    "We will use the [Iris plants dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset). It is a classic and very simple multi-class classification dataset. This dataset consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray. The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width. We use these four features for clustering. The true labels, see below `iris_data.target`, will be used to evaluate the performance of Kmeans method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28c3c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b59438c81c71d64add72bfd4c161d80",
     "grade": false,
     "grade_id": "cell-c684d69615e64ff0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "iris_data = load_iris()    # load the iris dataset\n",
    "X = iris_data.data    # obtain features of datapoints\n",
    "y = iris_data.target    # obtain labels of datapoints\n",
    "\n",
    "# shape of samples\n",
    "print(f'Shape of samples {X.shape}')    # print the shape of features\n",
    "print(f'Target names {iris_data.target_names}')    # print all label names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4416de1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5859757abf4e03759f80175bc0db8ef3",
     "grade": false,
     "grade_id": "cell-63abb32d8b36ef27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Defining and Training Model\n",
    "We use `KMeans()` and `.fit()` to train our model. Read more [parameter settings](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) in details. Please set the `random_state` as 0, and the `n_clusters` (which is the parameter k in k-means) so that you could hope to capture the different types of irises' - see the targets in the previous code cell; we'll be comparing those against K-means labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a9774",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14e274e24d21a209fc0b6c12de7e52c1",
     "grade": false,
     "grade_id": "cell-bec68413a1267151",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # define and train model\n",
    "\n",
    "# kmeans = ...\n",
    "# kmeans.fit(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c26ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bc8fd65ec393b4d0582fd57753081c2",
     "grade": true,
     "grade_id": "cell-8e665da375c4ed59",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for A4.1 tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd31c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8af6fa45c34a73bb4bc876f8fe283d1e",
     "grade": false,
     "grade_id": "cell-60b4fd73298f2464",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6caa3c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29fe19af1ccc28e137ec6b13d93c386d",
     "grade": false,
     "grade_id": "cell-ed469bd90fbb4684",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Cluster quality metrics evaluated (see [Clustering performance evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation) for definitions and discussions of the metrics):\n",
    "\n",
    "| Shorthand | full name |\n",
    "| ---- | ---- |\n",
    "| homo | homogeneity score |\n",
    "| compl | completeness score |\n",
    "| v-meas | V measure |\n",
    "| ARI | adjusted Rand index |\n",
    "| AMI | adjusted mutual information |\n",
    "| silhouette | silhouette coefficient |\n",
    "\n",
    "**NOTE**: Homogeneity/Completeness score, V measure, ARI and AMI are all **external validity indices** - so called since they require labels (i.e., external information). Silhouette coefficient on the other hand only requires the data points and cluster assignments, and is an example of an **internal validity index**. Validity indices can be used to evaluate single clustering, choose k, or compare multiple clusterings. However, there are some nuances in the use of these measures and how they should be used with different clustering models, which goes beyond this course.\n",
    "These and other validity indices are dealt with in more depth in the course CS-E4650 (Methods of Data Mining). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42f4fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ea7b7c759c47a31ad3fc2e27a5fbb9c",
     "grade": false,
     "grade_id": "cell-eedc2f4b91e3d8d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the running time\n",
    "t0 = time()\n",
    "estimator = KMeans(n_clusters=3, random_state=0, n_init = 10).fit(X)\n",
    "fit_time = time() - t0\n",
    "results = [fit_time, estimator.inertia_]\n",
    "\n",
    "# define the metrics which require only the true labels and estimator labels\n",
    "clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "]\n",
    "results += [m(y, estimator.labels_) for m in clustering_metrics]\n",
    "\n",
    "# the silhouette score requires the full dataset\n",
    "results += [\n",
    "        metrics.silhouette_score(\n",
    "            X,\n",
    "            estimator.labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "    )\n",
    "]\n",
    "\n",
    "# show the results of each metric and print them\n",
    "formatter_result = (\n",
    "        \"{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    ")\n",
    "print(66 * \"_\")\n",
    "print(\"time\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "print(formatter_result.format(*results))\n",
    "print(66 * \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d85a95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b04c0b57fa704de56234ccbe66a253c",
     "grade": false,
     "grade_id": "cell-d378aafa83cdc109",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's visualize the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f80b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "221722e457a88a3fb106e50c46d972c4",
     "grade": false,
     "grade_id": "cell-b646a12a3cb3953a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_    # obtain clustering labels\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(float), edgecolor='k')    # plot a scatter plot of labels vs. X with varying marker size or color\n",
    "ax.set_xticklabels([])    # leave the text values blank of the tick labels\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "ax.set_xlabel('Petal width')    # set the label for the x/y/z-axis\n",
    "ax.set_ylabel('Sepal length')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22084b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "241308b2a949d11b0f36907ae1bf3235",
     "grade": false,
     "grade_id": "cell-63ef7e9ab4a5abf7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='D4.1'></a>\n",
    "<div class=\" alert alert-info\" >\n",
    "    \n",
    "## Demo\n",
    "### The importance of initialization   \n",
    "    \n",
    "Here you can visually explore the sensitivity of K-means to initialization, and the effect standardization can have on it.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218c756",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6ce92e8f48b4456a66c826a63564fe0",
     "grade": false,
     "grade_id": "cell-d46d59708c30bdcd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The problem of finding k globally optimal centroids is strictly speaking too hard for us to solve in finite time. We can still find *good* solutions using an iterative approach (see 'algorithm 12' in ML book chapter 8.1). However, the solutions we find are only locally optimal and there is always the risk that we get stuck in a very suboptimal solution. Most importantly, this means that our solution depends on our initial guess for the centroids. Therefore, it is usually a good practice to run the K-means algorithm multiple times using different initial centroids, and then choose based on some goodness measure or a validation index - or if the data is low dimensional, based on visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383d32b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "362e16429b9dfcf1cd8007a8f63d5afc",
     "grade": false,
     "grade_id": "cell-6e474dd00a0370d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's create a toy dataset with 2 distinct clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be6f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Do not change the seed\n",
    "np.random.seed(0)\n",
    "n=500\n",
    "Xdemo=np.random.multivariate_normal([0,5/2],np.diag([20,5/8]),n)\n",
    "Xdemo=np.vstack((Xdemo,np.random.multivariate_normal([0,-5/2],np.diag([20,5/8]),n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71ef3a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5eacc6e644610900a78a22b607431297",
     "grade": false,
     "grade_id": "cell-9560bf7de6758492",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's choose 2 random points from the dataset as our initial cluster centroids, and then cluster and plot the result as well as the initial centroids. The 'n_init=1' is specifying that we do not want multiple re-starts of the algorithm, as we are using our own initial centroids.\n",
    "\n",
    "**NOTE**: You can keep running the cell multiple times (hold ctrl + press enter)\n",
    "\n",
    "**NOTE**: You can also try a more sophisticated initialization scheme ([`k-means++`](https://en.wikipedia.org/wiki/K-means%2B%2B))   - it is the sklearn's default K-means initialization when you don't provide the initial centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251683c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f60a18c9da8e43500ff2b83aff847cfc",
     "grade": false,
     "grade_id": "cell-444cb45ca02c8764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Here we use numpy's random.choice to choose indeces of inital centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71edc748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init=Xdemo[np.random.choice(np.arange(Xdemo.shape[0]),2, replace=False),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71b458",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0dbbf10283d17cffc3c2ebe1f3552d23",
     "grade": false,
     "grade_id": "cell-444cb45ca02c8764b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ...and then pass those initial centroids to K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b4504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=2, init=init, n_init=1).fit(Xdemo)\n",
    "\n",
    "plt.scatter(Xdemo[:,0],Xdemo[:,1],c=kmeans.labels_)\n",
    "plt.plot(init[:,0],init[:,1],'bo', markersize=7)\n",
    "plt.plot(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],'ro', markersize=7)\n",
    "plt.xlim([-15,15])\n",
    "plt.ylim([-6,6])\n",
    "plt.title('Blue dots initial, Red dots final centroids')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937d5d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5451e5ed97a3de649eed5819de1c7a31",
     "grade": false,
     "grade_id": "cell-33877679efa229a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Only very rarely are the initial centroids chosen such that the algorithm is able to distinguish the 2 distributions (if you keep running the cell you will eventually succeed).  \n",
    "\n",
    "In this particular case, we can try to mitigate this sensitivity to initialization by standardizing our features using Sklearn's ['StandardScaler'](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a716ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sklearn way\n",
    "Xs = StandardScaler().fit_transform(Xdemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5579ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual way\n",
    "#Xs = (Xdemo-Xdemo.mean(axis=0))/Xdemo.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e303155",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d562e1293e60fce345b8376073407ade",
     "grade": false,
     "grade_id": "cell-6c2cff7e75a031b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**And again using either randomly chosen data points or k-means++ for initial centroids:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c9733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial centroids as random data points\n",
    "init=Xs[np.random.choice(np.arange(Xs.shape[0]),2, replace=False),:]\n",
    "kmeans=KMeans(n_clusters=2, init=init, n_init=1).fit(Xs)\n",
    "\n",
    "plt.scatter(Xs[:,0],Xs[:,1],c=kmeans.labels_)\n",
    "plt.plot(init[:,0],init[:,1],'bo', markersize=7)\n",
    "plt.plot(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],'ro', markersize=7)\n",
    "plt.title('Blue dots initial, Red dots final centroids')\n",
    "plt.xlabel('X1 (scaled)')\n",
    "plt.ylabel('X2 (scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85f23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7adda5b91c5418bf53be56535e8a6c",
     "grade": false,
     "grade_id": "cell-b1ef61bb1eee072d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(NOTE the different X1, X2 scales)**\n",
    "\n",
    "Now K-means has no trouble finding the clusters, even with poor initial centroids. As to the effectiveness of scaling, this is a somewhat \"cherry-picked\" example: In real world task, decision to normalize or standardize your data should be based on your understanding of the data. E.g., if there are features that do not have the same units and are on wildly differing scales, while your prior assumption is that those features are likely to be equally significant for the learning task; it is appropriate to standardize them. However, if your features have the same units (e.g., both are m/s) and you have no information based on which you could conclude about their relative significance, you should not scale the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88600e44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8131012319a190a3374057fdc311070a",
     "grade": false,
     "grade_id": "cell-39da174d5a072780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='A4.2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.2:\n",
    "Standardization clearly had an effect on convergence in the previous demo. Based on the scatter plot of the data, could you come up with an even simpler feature transformation that would make the clustering task easier? If you feel unsure about the answer, you can always modify the previous demo and try different approaches, or plot histograms of the features. Answer by setting the 'Answer' variable to the index of the answer that you consider correct. \n",
    "    \n",
    "* Answer 1: Shift the data by some constant factor.\n",
    "* Answer 2: Use just one of the features - either one will work.\n",
    "* Answer 3: Use just one of the features - 2nd feature will work.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d1b8b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d3014da53ab4bb97be700c0569cdf1a",
     "grade": false,
     "grade_id": "cell-61556728b176c5c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set Answer to the index of the correct answer (e.g., Answer = 1 if you think Answer 1 is correct)\n",
    "\n",
    "# Answer  = ...   \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# sanity check datatype of Answer_Q1\n",
    "assert isinstance(Answer, int), \"Please use datatype 'int' for your answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538519e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc415324704422415ad471cac8941b9f",
     "grade": true,
     "grade_id": "cell-1f48a70cb00b0f54",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the test cell for A4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b822a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51b1f5c45c2e89c4512f02f0ef7b223e",
     "grade": false,
     "grade_id": "cell-83f38ff16fc706a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='D4.2'></a>\n",
    "<div class=\" alert alert-info\" >\n",
    "    \n",
    "## Demo\n",
    "    \n",
    "### The nature of K-means solutions.\n",
    "    \n",
    "Here we can inspect how the clustering evolves through iterations. As explained, in addition to minimizing inertia, the K-means objective is implicitly also maximizing the separation between clusters:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdda4cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4450c2924e0d4447e640c6c92d34c5f",
     "grade": false,
     "grade_id": "cell-ec82d67c72be26d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "K-means aims to minimize:\n",
    "\n",
    "$$\n",
    "\\sum^{}_{x_i\\in C_j}\n",
    "\\| x_i - \\mu_j\\|^2\n",
    "$$\n",
    "\n",
    "for each cluster. Equivalently we could minimize within-cluster pairwise squared deviations:\n",
    "\n",
    "$$\n",
    "\\dfrac{1}{\\mid C_j\\mid}\n",
    "\\sum^{}_{x,y\\in C_j}\n",
    "\\| x - y\\|^2\n",
    "$$\n",
    "\n",
    "and as the total variance in the data remains constant, minimizing the within-cluster deviations will also result in maximizing the pairwise deviations for data points in different clusters (between-cluster deviations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806087bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a28190360e0efd8a87f1ded8f8ed6dfc",
     "grade": false,
     "grade_id": "cell-8ae1b56f4bc7ffd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**NOTE: You can change the random seed to test different initializations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32990999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: this cell is editable\n",
    "np.random.seed(6)   \n",
    "\n",
    "#Alias for pairwise distance function\n",
    "DIST=metrics.pairwise_distances\n",
    "init=Xs[np.random.choice(np.arange(Xs.shape[0]),2),:]\n",
    "total_deviations=(DIST(Xs,Xs)**2).sum()/Xs.shape[0]\n",
    "inertia=[]\n",
    "between=[]\n",
    "within=[]\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Hold previous value of inertia to determine when the clustering\n",
    "# stops improving (initial value can be any large value)\n",
    "inertia_prev = 1e12\n",
    "plt.subplot(2,2,1)\n",
    "for i in range(1,100):\n",
    "    \n",
    "    # We are manually iterating with KMeans \n",
    "    kmeans=KMeans(n_clusters=2, init=init, n_init=1, max_iter=1).fit(Xs)\n",
    "    plt.scatter(Xs[:,0],Xs[:,1],c=kmeans.labels_)\n",
    "    plt.xlabel('X1 (scaled)')\n",
    "    plt.ylabel('X2 (scaled)')\n",
    "    if(i==1):\n",
    "        plt.plot(init[:,0],init[:,1],'bo', markersize=9)   \n",
    "    else:\n",
    "        plt.plot(init[:,0],init[:,1],'ro', markersize=i)\n",
    "    \n",
    "    #Hold the centroids for next iteration\n",
    "    init=kmeans.cluster_centers_\n",
    "    \n",
    "    n0=np.sum(kmeans.labels_==0) # number of points in cluster 0\n",
    "    n1=np.sum(kmeans.labels_==1) # number of points in cluster 1\n",
    "    x0=Xs[np.where(kmeans.labels_==0)[0],:] #points in cluster 0\n",
    "    x1=Xs[np.where(kmeans.labels_==1)[0],:] #points in cluster 1\n",
    "    w0 = .5*(DIST(x0,x0)**2).sum()/n0 # deviations within cluster 0\n",
    "    w1 = .5*(DIST(x1,x1)**2).sum()/n1 # deviations within cluster 1\n",
    "    \n",
    "    \n",
    "    inertia.append(kmeans.inertia_)\n",
    "    within.append( w0 + w1 )\n",
    "    between.append( total_deviations - w0 - w1 )\n",
    "    \n",
    "    if(np.isclose(kmeans.inertia_,inertia_prev, rtol=1e-3)):\n",
    "        plt.title('Blue dots initial, (Biggest) red dots final centroids')\n",
    "        print('Stop Iteration at')\n",
    "        print('{}th step'.format(i))\n",
    "        print('Final centroids: \\n{}'.format(np.round(kmeans.cluster_centers_,2)))\n",
    "        break\n",
    "    else:\n",
    "        inertia_prev=kmeans.inertia_\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(np.arange(1,len(inertia)+1),inertia)\n",
    "plt.title('Inertia')\n",
    "plt.xlabel('iter')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(np.arange(1,len(between)+1),between)\n",
    "plt.title('Between cluster deviations')\n",
    "plt.xlabel('iter')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(np.arange(1,len(within)+1),within)\n",
    "plt.title('Within cluster deviations')\n",
    "plt.xlabel('iter')\n",
    "plt.gcf().tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a3210",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "551fb3037870c220aef22bd54c5d9410",
     "grade": false,
     "grade_id": "cell-7d39c855c9dd809f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='A4.3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student task A4.3. Choosing k for K-means.\n",
    "\n",
    "Now, your task is to use inertia and silhouette coefficient to choose a good value for parameter k. \n",
    "    \n",
    "You can use [`sklearn.cluster.KMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) to construct the model, it's attribute **.inertia_** for inertia, and [`sklearn.metrics.silhuette_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) for silhuette coefficient. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d30434",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9aa101975c43a96f23de16e75b42c5dc",
     "grade": false,
     "grade_id": "cell-fcc8ea09f1ac5ab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The K-means model requires us to provide the parameter k. With low-dimensional or otherwise trivial data this might be easy to conclude based on visual exploration. However, in many real world scenarios it is hardly a trivial task. In addition to previously mentioned validity indices, the value of the clustering objective (**inertia**) itself can be used to evaluate the clustering at different values of k. And properly interpreted, the inertia can help us to choose the value for k. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235f0bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3b5148c225537972b3e007dd56563c9",
     "grade": false,
     "grade_id": "cell-01bcda143ded739d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The most basic approach to choosing k is called **the elbow method**. In elbow method we plot the value of inertia with different values of k, and choose the smallest k that produces \"sufficiently low values of inertia.\" In practice this is done by looking for the point where the inertia plot is becoming less steep (\"elbow\" in the curve). This typically occurs when K-means is in some sense starting to overfit, i.e., instead of adding new clusters to capture truly separated sets of data points, it is starting to partition already compact clusters into smaller parts which are not well separated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4af2f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1673f174bf787d0a3e9efd52bd56500f",
     "grade": false,
     "grade_id": "cell-2e614c0ca4406916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As an additional method, we also use Silhuette coefficient/index (**SI**) to infer a good value for k. Higher values are better, and ideally we'd hope to find a peak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83232c42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0840589b7be595fe8a9b5593869e06b4",
     "grade": false,
     "grade_id": "cell-30b671e04d31c651",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's load and visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e32db1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e95b682d249fece5c09614171979fd94",
     "grade": false,
     "grade_id": "cell-f3993540bf70c236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('chooseK.csv').to_numpy()\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b42e103",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b89af1dd0e1d211cdf27d3fa5cbfa4e7",
     "grade": false,
     "grade_id": "cell-6b61a185f9c3b8c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Your task:\n",
    "\n",
    "Fit K-means model using the whole data X, for each value of k=2,3,...,6, and calculate SI for each instance and collect the inertias and SI's in python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9838e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ccad58684d7197c32750df6f38d8aff",
     "grade": false,
     "grade_id": "cell-a7e0b654c9932cf2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## append the si and inertia values to these lists \n",
    "inertia = []\n",
    "SI = []\n",
    "\n",
    "\n",
    "## Write a loop, and within it fit Kmeans on X with k=2,3,...,7 clusters\n",
    "## using following variable names:\n",
    "\n",
    "# for k in range(2, 8):\n",
    "\n",
    "    ## initialize and train the model (for each k), it is recommended to use\n",
    "    ## large enough value (e.g. 10) for n_init to ensure good results\n",
    "    # kmeans = \n",
    "    \n",
    "    ##calculate si\n",
    "    # si = \n",
    "    \n",
    "    ##...and append SI and inertia (for each k) to corresponding lists\n",
    "    # inertia...\n",
    "    # SI...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# sanity check\n",
    "assert len(SI) == len(inertia) == 6 , \"You should be getting 6 values for SI and inertia!\"\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(2,8),inertia)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(np.arange(2,8))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(2,8),SI)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SI')\n",
    "plt.xticks(np.arange(2,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16c982",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8538d4f06f02ec47c003d0cb6d54de7",
     "grade": true,
     "grade_id": "cell-854cef1165b2c39a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for A4.3 tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb3b91-0841-4d64-ae47-a4f10bd094d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "000ac18d14bbe07af6aacbe8a6d5d334",
     "grade": false,
     "grade_id": "cell-48f4032010d93fe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='A4.4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.4:\n",
    "    \n",
    "Based on the plotted Inertia and SI, which k (number of clusters) would be the best choice?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc41d4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "755e80d31db8cc605ce0d9100a52448f",
     "grade": false,
     "grade_id": "cell-d1e37b17afd8d78f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set variable Best_k to the correct answer (e.g., Best_k=2 if you think answer k=2 is correct)\n",
    "\n",
    "# Best_k  = ...  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ba68b-fd27-47ae-af03-6c52817da978",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "516101fe3f0ef199f6ee0831b550945f",
     "grade": true,
     "grade_id": "cell-119c41cbde9ba05d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for A4.4 tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf063",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9c6315f396e6a5ba6eac7226a8072f4",
     "grade": false,
     "grade_id": "cell-6476bd9df8b9c5b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "km=KMeans(n_clusters=Best_k, n_init=10).fit(X)\n",
    "plt.scatter(X[:,0],X[:,1], c=km.labels_)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66172b8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "651b957f1615fb930677a16a0bba9838",
     "grade": false,
     "grade_id": "cell-f9ad7eb41dd68b5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='D8.3'></a>\n",
    "<div class=\" alert alert-info\" >\n",
    "    \n",
    "## Demo\n",
    "    \n",
    "### The nature of K-means solutions (continued).\n",
    "    \n",
    "We can also inspect how the algorithm partitions the input space. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7e8c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa48793d78d2820077f791bd8454c08c",
     "grade": false,
     "grade_id": "cell-1e65f9522c458fdd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('chooseK.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf68785",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e91d3e81e75f568e5033fe69d60ba946",
     "grade": false,
     "grade_id": "cell-02b04c27d14dded0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use the same data as in the previous task. First, let's create a meshgrid over the input space - this helps us to visualize the cluster assignments in the input space more broadly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67502a44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02cd79e08c747ef6a9fd96c49e128824",
     "grade": false,
     "grade_id": "cell-2f3978e6f4328e66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xx,yy = np.meshgrid(np.linspace(-2,3.0,100),np.linspace(-2.5,4,100))\n",
    "xx,yy=xx.reshape(-1,1),yy.reshape(-1,1)\n",
    "XX=np.hstack((xx,yy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06f272",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38ef52fe643860100a7400839f23d613",
     "grade": false,
     "grade_id": "cell-9b64ad005b3380da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then, we create an iteration counter and choose initial centroids at random from the data. \n",
    "\n",
    "**NOTE:** You need to run this cell before starting to run the cell after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe648b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(1) #remove or comment-out this line to test different initializations\n",
    "it=0\n",
    "inertia_prev=1e12\n",
    "init=X[np.random.choice(np.arange(X.shape[0]),Best_k, replace=False),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679c321",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a43f78c85a31d41dc37b4b5de5ac16d5",
     "grade": false,
     "grade_id": "cell-f66b3f10288447d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we can run the K-means one iteration at the time, by setting 'max_iter=1' and taking the new updated centroids as the next initial points. We are also using the trained K-means instance to predict for those previously created grid points.\n",
    "\n",
    "**NOTE:** You can hold 'Shift' and press 'Enter' to run the cell one time. When the clustering objective is no longer improving, the code will print a message to stop iterating. If you wish to repeat this task, e.g., with different initial points, just run the above code cell again with necessary modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=Best_k, init=init, n_init=1, max_iter=1).fit(X)\n",
    "init=kmeans.cluster_centers_\n",
    "it+=1\n",
    "\n",
    "if(np.isclose(kmeans.inertia_,inertia_prev, rtol=1e-3)):\n",
    "        print('Stop Iteration at')\n",
    "        print('{}th step'.format(it))\n",
    "else:\n",
    "    inertia_prev=kmeans.inertia_\n",
    "    \n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(init[:,0],init[:,1],'ro', markersize=7)\n",
    "plt.scatter(xx,yy,c=kmeans.predict(XX), alpha=.8)\n",
    "plt.scatter(X[:,0],X[:,1],c=kmeans.predict(X),edgecolors='black')#'blue')\n",
    "plt.title('Red dots are current centroids, and other colors refer to cluster assignments')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203ad5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b65f690c0220527ca3b9f6a4a526a4c1",
     "grade": false,
     "grade_id": "cell-77518d3bf2ec714e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='A8.4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.5:\n",
    "    \n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: For an arbitrary dataset, can we choose k such that clustering error goes to zero?\n",
    "- Answer 1: Yes\n",
    "- Answer 2: No\n",
    "- Answer 3: It depends on the data.  \n",
    "\n",
    "Question 2: Do you agree with the following statement: Lower clustering (mean distance to centroids) error always indicates a more usable model.\n",
    "- Answer 1: Yes.\n",
    "- Answer 2: No.  \n",
    "\n",
    "Question 3: Do you agree with the following statement: Scikit-learn function kmeans.fit( ) might find different number of cluster means/centroids than the given k (n_clusters parameter).\n",
    "- Answer 1: Yes.  \n",
    "- Answer 2: No.\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22c091",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51ab5f2598b5cb3f6c4cbff8a95b2203",
     "grade": false,
     "grade_id": "cell-b974857a134c3df3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "\n",
    "# Answer_Q1  = ...  \n",
    "\n",
    "## set Answer_Q2 to the index of the correct answer for Question 2 \n",
    "\n",
    "# Answer_Q2 = ...   \n",
    "\n",
    "## set Answer_Q3 to the index of the correct answer for Question 3 \n",
    "\n",
    "# Answer_Q3 = ... \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# sanity check datatype of Answer_Q1\n",
    "assert isinstance(Answer_Q1, int), \"Please use datatype 'int' for your answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381e990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da4bb4191276a9d122b35c8f8e1c8f00",
     "grade": true,
     "grade_id": "cell-8be0e1e7827f94fc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for A4.5 tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c622e44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f535930f843804ac5923dbbf20c17c32",
     "grade": true,
     "grade_id": "cell-8c07fc0892d12878",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for A4.5 tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50d7ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f02cb26b2618ec3b8d57ddbe662c3e2",
     "grade": true,
     "grade_id": "cell-658d187c0266b059",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for A4.5 tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf4ce1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9fc47909629474e747e0950df20575a",
     "grade": false,
     "grade_id": "cell-87889c88927864db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='A8.5'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student task A4.6. \n",
    "    \n",
    "### Using clustering to construct new features.\n",
    "\n",
    "Now, your task is to leverage K-means clustering to construct new features for a supervised learning task using linear regression.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fbfa0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361e8c8a337a4efbf204b356a49a9641",
     "grade": false,
     "grade_id": "cell-7b7218b79ca50503",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assuming our dataset consists of four data points:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{X} = \\begin{pmatrix}\n",
    "                  x^{(1)}   \\\\\n",
    "                  x^{(2)}   \\\\\n",
    "                  x^{(3)}   \\\\\n",
    "                  x^{(4)} \n",
    "               \\end{pmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "which have been clustered into 2 clusters according to: \n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{Y} = \\begin{pmatrix}\n",
    "                  0   \\\\\n",
    "                  0   \\\\\n",
    "                  1   \\\\\n",
    "                  1 \n",
    "               \\end{pmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "We can construct new features $\\mathbf{x_1,x_2}$ using the cluster assignments. We do it using the following logic: If the i'th data point $x^{(i)}$ is assigned to cluster 0, we set $x_1^{(i)}=x^{(i)}$, and if it is assigned to cluster 1, we set $x_2^{(i)}=x^{(i)}$. Our 4 datapoints, first 2 assigned to cluster 0, and the last 2 to cluster 1, would produce the following features:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{X_{new}}= \\begin{pmatrix}\n",
    "                  x^{(1)} & 0  \\\\\n",
    "                  x^{(2)} & 0  \\\\\n",
    "                  0 & x^{(3)}  \\\\\n",
    "                  0 & x^{(4)}\n",
    "               \\end{pmatrix} \n",
    "               = \\begin{pmatrix}\n",
    "                  x_1^{(1)} & x_2^{(1)} \\\\\n",
    "                  x_1^{(2)} & x_2^{(2)} \\\\\n",
    "                  x_1^{(3)} & x_2^{(3)} \\\\\n",
    "                  x_1^{(4)} & x_2^{(4)}\n",
    "               \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "This is effectively the same as partitioning the data using the cluster assignments into 2 (or k more generally) disjoint datasets and training a distinct model with each partition. So, with the previous example we would get 2 models:\n",
    "\n",
    "$$\n",
    "Model_1: \\alpha_1 x_1 + \\beta\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Model_2: \\alpha_2 x_2 + \\beta\n",
    "$$\n",
    "\n",
    "However, this approach is limited by the fact that both models have a shared constant term $\\beta$, which may or may not be appropriate for the task at hand. We can make the \"combined\" model slightly more expressive by adding a separate constant term $\\mathbf{x_c}$ in our features for cluster 1:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{X_{new}}= \\begin{pmatrix}\n",
    "                  x^{(1)} & 0 & 0 \\\\\n",
    "                  x^{(2)} & 0 & 0  \\\\\n",
    "                  0 & x^{(3)} & 1  \\\\\n",
    "                  0 & x^{(4)} & 1\n",
    "               \\end{pmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "which equals training 2 full models (on their respective partitions of the data):\n",
    "\n",
    "$$\n",
    "Model_1: \\alpha_1 x_1 + \\beta_1\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Model_2: \\alpha_2 x_2 + \\beta_2 \\\\\n",
    "$$\n",
    "or a combined model:\n",
    "$$\n",
    "Model_{1,2}: \\alpha_1 x_1 + \\alpha_2 x_2 + \\beta_2 x_c + \\beta_1\n",
    "$$\n",
    "\n",
    "(this parameterization assumes the linear model has an intercept term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc96ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7edb5da4d38f5b60a6f91b95cf4e91c4",
     "grade": false,
     "grade_id": "cell-058771cca8a05fa1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Below is a class for constructing the features:\n",
    "\n",
    "**Study how the class is implemented, and what are the parameters. Its fit, transform and fit_transform addhere to the same logic as sklearn's classes you have previously used.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911ebed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bab9ab375231b5b8894845d365b987d1",
     "grade": false,
     "grade_id": "cell-31b8feb9fccf8dbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClusteredFeatures:\n",
    "    \n",
    "    def __init__(self, n_clusters, add_constant=False, random_state=0):\n",
    "        self.random_state = random_state\n",
    "        self.n_clusters=n_clusters\n",
    "        self.add_constant=add_constant\n",
    "        self.kmeans=None\n",
    "    \n",
    "    def fit(self,x):\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, n_init = 10, random_state=self.random_state).fit(x)\n",
    "    \n",
    "    def transform(self,x):\n",
    "        assert self.kmeans is not None, 'You have to call fit before transform!'\n",
    "        \n",
    "        #Number of clusters\n",
    "        k=self.kmeans.n_clusters\n",
    "        #Cluster assignments\n",
    "        assignments=self.kmeans.predict(x)\n",
    "\n",
    "        #Initialize new features as zeros\n",
    "        x_new=np.zeros((x.shape[0],k))\n",
    "        # This creates a boolean indices\n",
    "        bool_ind=(np.arange(k).reshape(-1,1)==assignments).T\n",
    "        # Set new features to input features based on boolean indices\n",
    "        x_new[bool_ind]=x.reshape(-1)\n",
    "\n",
    "        #Add k-1 constant terms\n",
    "        if(self.add_constant):\n",
    "            for j in range(1,k):\n",
    "                ones = np.zeros((x.shape[0],1))\n",
    "                ones[np.where(assignments==j)]=1\n",
    "                x_new=np.hstack((x_new,ones))\n",
    "\n",
    "        return x_new\n",
    "        \n",
    "    def fit_transform(self, x):\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36815e28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87a4f14d39414d2d216e40865bd0b4b2",
     "grade": false,
     "grade_id": "cell-ac6f101b73798c63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is an \"alias\" for mse function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317dfa0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5558932d0121d15432d38657297b59fa",
     "grade": false,
     "grade_id": "cell-be446091435c6dde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MSE = mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b6726",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bddbd19dde4ba8b6cb780743be776e0",
     "grade": false,
     "grade_id": "cell-673ec1b05edf30b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "you can use it in place of the mean_squared_error function. This is sometimes handy to make your code more concise and less cluttered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8e06d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c62d89fcd1fd417f2d81fe58d4049e2",
     "grade": false,
     "grade_id": "cell-1e40eb8ce0f50e9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Let's load some toy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aae237",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94442f8f45e1692fce1de89ea56682fc",
     "grade": false,
     "grade_id": "cell-2d0931d0b0192a3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('featuresK.csv').to_numpy()\n",
    "x_train,y_train = data[:,0].reshape(-1,1),data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23f3d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8e19a116a46c2da4fe87c5d4e6d6c7c",
     "grade": false,
     "grade_id": "cell-0b4515f557249f4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "... and see how the data is clustered (based on the feature alone):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99702fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e854cfd436b142a6f3feaf424ee33e29",
     "grade": false,
     "grade_id": "cell-f81d4b6ec5e5cbad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2, n_init = 10).fit(x_train)\n",
    "plt.scatter(x_train,y_train,c=km.labels_)\n",
    "plt.xlabel('X (feature)')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7390e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18577a5f53e9d599c2e4048f8b80918b",
     "grade": false,
     "grade_id": "cell-edd2ee211e3a33fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's train a simple LinearRegression on the training data. We will also define a grid of evaluation points for predicting with the trained model. We use numpy's [`linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) to get 50 equally spaced data points $x_{eval}\\in[0,9]$. This linear model is our baseline solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741edde8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b51d3648bb350bef01f4285cc651ad0f",
     "grade": false,
     "grade_id": "cell-f9dbc58fa16672e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Baseline model\n",
    "lm=LinearRegression().fit(x_train,y_train)\n",
    "#Evaluation points \n",
    "x_eval = np.linspace(0,9, 50).reshape(-1,1)\n",
    "#prediction using the evaluation points (for plotting)\n",
    "y_eval=lm.predict(x_eval)\n",
    "#predictions for training error\n",
    "yhat_train=lm.predict(x_train)\n",
    "mse_train=MSE(y_train, yhat_train)\n",
    "\n",
    "#plotting the results\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x_eval,y_eval,'k-')\n",
    "plt.scatter(x_train,y_train, c=km.labels_)\n",
    "plt.title('training error: {}'.format(round(mse_train,2)))\n",
    "plt.xlabel('X (feature)')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a56b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a2a6e571df26cfa76fc87dc61f165ed",
     "grade": false,
     "grade_id": "cell-14ebeb3a08cd3ee8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Clearly, the data seems to have 2 different modalities, and the fit is a compromise between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926d275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## In this cell, you can first try ClusteredFeatures\n",
    "## with a small subset of data, for example with x_train[:10]\n",
    "## and see how the class works. There are no tests for this (not mandatory).\n",
    "\n",
    "# x_tmp = x_train[:10]\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b361994",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef952fab54f3199e71be84fb0250d6f9",
     "grade": false,
     "grade_id": "cell-bbd15864589c042c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Now, your task is to try to improve the model with clustered features:\n",
    "\n",
    "**You can use the same grid of evaluation points $x_{eval}$. In this code cell you only need to construct the features, and in the next one you train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead55b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3b7f20634ef3f4f06e127be2c2716a0",
     "grade": false,
     "grade_id": "cell-f940886ee305e7fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Construct the features from both x_train and x_eval (no need to use them here).\n",
    "## You need to use \"ClusteredFeatures\" class, and it's fit and transform functions.\n",
    "## Set the number of clusters appropriately to capture both modalities in the data.\n",
    "## Set add_constant=True, and leave random_state=0\n",
    "\n",
    "\n",
    "# cf = ClusteredFeatures(n_clusters= ..., add_constant= ...)\n",
    "\n",
    "# xnew_train = \n",
    "# xnew_eval = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Sanity check\n",
    "assert type(cf)==ClusteredFeatures , \"You need to use ClusteredFeatures class\"\n",
    "assert xnew_train.shape[1]==xnew_eval.shape[1]==3, 'You should be getting 2k-1 features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf2cb3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e8fb1c13d59bf2b1631f1dd9c82b05d",
     "grade": true,
     "grade_id": "cell-4601a1bad61ade2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is for A4.5 tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a5f73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30869747bf3a0c886bbd9771b6cd7cfd",
     "grade": false,
     "grade_id": "cell-6bd10e1176c9e0e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### And now you need to fit the model on those features, predict and calculate the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2814db9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e3ce824b1a87121b0aef6cd3d3d6f6",
     "grade": false,
     "grade_id": "cell-f6df3c4b18cd23df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fit linear model (lm), with intercept term, using training data with new features\n",
    "## and then predict using both evaluation and training data, and compute training error\n",
    "\n",
    "# lm = \n",
    "# yhat_eval = \n",
    "# yhat_train = \n",
    "# mse_train = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x_eval,yhat_eval,'k-')\n",
    "plt.scatter(x_train,y_train, c=km.labels_)\n",
    "plt.xlabel('X (feature)')\n",
    "plt.ylabel('Y')\n",
    "plt.title(\"training error: {}\".format(round(mse_train,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be839c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13f9533d9429976c59787013ccee340b",
     "grade": true,
     "grade_id": "cell-93d69bfcc6b0cb37",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b28e9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "366d278c89461917442d02c49332f3ab",
     "grade": true,
     "grade_id": "cell-585701c7f28df330",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cells is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff5c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#You can try constructing features with different values of k, and fitting models with them.\n",
    "# You can copy-paste some of the previous code, but do not copy \n",
    "# entire cells without acttivating them first (\"enter\" into the cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa930ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc44e87e4c42f4b084e8068817d790da",
     "grade": false,
     "grade_id": "cell-6655aae7d9da22c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78d640",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92fe38c388ba5cbb9c3316b2c454de8d",
     "grade": false,
     "grade_id": "cell-29b9f76d3640c010",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this section we will build a naive Bayes classfier for spam detection. Earlier on this course logistic regression was used for classification.\n",
    "\n",
    "We will be using Youtube comments extracted from five different videos as our training and test data. Each comment is labeled either as spam or ham (non-spam). Class label 1 is used for the spam and class label 0 is used for the ham."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e491343",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca0bbe3495122fc385f6fadb6cdafb3b",
     "grade": false,
     "grade_id": "cell-76a6fa1517d45180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading data\n",
    "\n",
    "We extract one third of the data set for testing the method later. Let us start by taking a look out our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd48163",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc08c576a00160d63cb6234b2f298c1b",
     "grade": false,
     "grade_id": "cell-421988f9e3a7eb45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('youtube_comments.csv')\n",
    "\n",
    "training_comments = comments[len(comments) // 3:]\n",
    "testing_comments = comments[:len(comments) // 3]\n",
    "\n",
    "# Let's print five training examples\n",
    "training_comments[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887e09e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93bf39d84d6f06f03811d04f321789c8",
     "grade": false,
     "grade_id": "cell-c4e2ee898c3b78ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "We want to build a naive Bayesian word based spam classifier based on Bayesian ideas. Let us first remind ourselves of the basic Bayesian concepts. A conditional probability is the probability that a random variable will take on a particular value given that the outcome for another random variable is known. For example, the conditional probability $P(Y = y | X = x)$ is the probability that the variable $Y$ will take on the value $y$, given that the variable $X$ is observed to have the value $x$.\n",
    "\n",
    "Bayes' theorem is stated mathematically as the following equation:\n",
    "\n",
    "$$P(Y | X) = \\frac{P(Y)\\cdot P(X | Y )}{P(X)}.$$\n",
    "\n",
    "$P(Y | X)$ is the degree of belief in $Y$ after $X$ is observed (*posterior*), which is computed from $P(Y)$, i.e. the initial (*prior*) degree of belief in the hypotesis $Y$, and $\\frac{P(X | Y )}{P(X)}$, i.e. the impact of the evidence $X$ on the probability of $Y$. For this reason, Bayes' formula can be intepreted as:\n",
    "\n",
    "$$\\text{posterior} = \\frac{\\text{prior}\\cdot\\text{likelihood}}{\\text{evidence}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710721a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e86bd72928751e920190280d255c0bff",
     "grade": false,
     "grade_id": "cell-b740ed3ac5b05045",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bayesian Spam Detection\n",
    "\n",
    "Numerous different ways to apply the Bayes formula to spam detection exist. We are going to make strong independece assumptions, resulting in so called naive Bayesian classifier.\n",
    "\n",
    "Let us now denote the spam status of a comment as $S$ s.t $S = 1$ if the comment is spam and $S = 0$ if the comment is not spam. Let us then denote the words of the comment as $W_1, \\dots, W_n$. We are going to assume conditional independence of the words $W_i$, given the class label $S$. This can be written mathematically as\n",
    "$$\n",
    "P(W_1, \\dots, W_n|S) = \\prod_{i=1}^n P(W_i|S).\n",
    "$$\n",
    "\n",
    "Generally, the words in a comment are not independent. However, considering them as being independent is a useful simplification, since we don't have enough information on the statistical correlations. Therefore, now that we have individual words probabilities inside the class 'spam' and inside the class 'ham', we can combine the probabilities of each of the words in a sentence to compute the probability of the sentence to be spam and the probability to be ham, and train our super naive classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616921d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "781ed781fa64c0b181ad71febd631b29",
     "grade": false,
     "grade_id": "cell-367b7ec2485ac4be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.7\n",
    "\n",
    "Which of the following formulas is the correct posterior probability under the assumptions given above:\n",
    "\n",
    "1.\n",
    "$$\n",
    "P(S=1|W_1, \\dots, W_n) =\n",
    "\\frac{\n",
    "    P(S = 1)\\cdot \\prod_{i=1}^n P(W_i|S=0)\n",
    "}{\n",
    "    P(S = 1) \\cdot \\prod_{i=1}^n P(W_i|S=0) + P(S = 0) \\cdot \\prod_{i=1}^n P(wW_i|S=1)\n",
    "}\n",
    "$$\n",
    "2.\n",
    "$$\n",
    "P(S=1|W_1, \\dots, W_n) =\n",
    "\\frac{\n",
    "    P(S = 1)\\cdot \\prod_{i=1}^n P(W_i|S=1)\n",
    "}{\n",
    "    P(S = 0) \\cdot (\\prod_{i=1}^n P(W_i|S=0) + \\prod_{i=1}^n P(W_i|S=1))\n",
    "}\n",
    "$$\n",
    "3.\n",
    "$$\n",
    "P(S=1|W_1, \\dots, W_n) =\n",
    "\\frac{\n",
    "    P(S = 1)\\cdot \\prod_{i=1}^n P(W_i|S=1)\n",
    "}{\n",
    "    P(S = 1) \\cdot \\prod_{i=1}^n P(W_i|S=1) + P(S = 0) \\cdot \\prod_{i=1}^n P(W_i|S=0)\n",
    "}\n",
    "$$\n",
    "    \n",
    "Write your answer as either $1$, $2$ or $3$ into the variable \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1e0a3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "976b7f787abeeca3fdee2290d4217090",
     "grade": false,
     "grade_id": "cell-95999525d916562e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create a variable as e.g.:\n",
    "# correct_posterior = 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e514f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dab7a4d0eca45a5854ba9a1c39c9222a",
     "grade": true,
     "grade_id": "cell-769cfd9d7cadfcdc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722a686",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d00d63f084d539acd53463f1446e32dd",
     "grade": false,
     "grade_id": "cell-d2bfc8584d39f04b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To calculate the posterior probability we will need the probabilities $P(S = 1) = 1- P(S = 0)$ and $P(W_i|S)$. All of these can be estimated from the data.\n",
    "\n",
    "Let us start by estimating the probability $P(S = 1)$ as the proportion of the comment being spam out of all the comments in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c52a73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8de133f4c41fb1c651765db4cffb5a1",
     "grade": false,
     "grade_id": "cell-c9a4145f53db295c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.8\n",
    "\n",
    "- Calculate the prior probability for a comment being spam $P(S=1)$ based on our training data set and store the result in variable `prior_spam_probability`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb2747",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2bfad1729b66853018d8763a69532df",
     "grade": false,
     "grade_id": "cell-693b683d561a0127",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create a variable as:\n",
    "# prior_spam_probability = # prior probability of a comment being spam based on the training data set\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdd57c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a72d036737100fe1e57a0a17cefc2a6f",
     "grade": true,
     "grade_id": "cell-6fe163379d296388",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001192c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "822881e839bde0e4cda142b81942825e",
     "grade": false,
     "grade_id": "cell-95c485a126c3d5c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next we want to estimate the likelihoods $P(W_i|S = 1)$ and $P(W_i|S = 0)$ which should reflect probility of a random word being that particular word in the given class. Hence we can estimate them by counting the frequency of the word in the class and dividing it by the total amount of words in the class.\n",
    "\n",
    "Let us start by extracting the frequency of each word in both of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b1176",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7434996a22fa4d6b6bc554e9222bd79e",
     "grade": false,
     "grade_id": "cell-52feefefed835a91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_words(string):\n",
    "    \"\"\"Extracts alphanumeric words from a string into a list\"\"\"\n",
    "    return findall(\"[a-z0-9äö']+\", string)\n",
    "\n",
    "def extract_frequencies(dataframe, column):\n",
    "    \"\"\"Extracts frequencies of words from the given column\"\"\"\n",
    "    return dataframe[column].str.lower().apply(find_words).explode().value_counts()\n",
    "\n",
    "spam_word_frequencies = extract_frequencies(training_comments.query('CLASS == 1'), 'CONTENT')\n",
    "ham_word_frequencies = extract_frequencies(training_comments.query('CLASS == 0'), 'CONTENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bcd84",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "444d59321bc83a862dc777ae962db3f6",
     "grade": false,
     "grade_id": "cell-1e9d7f21fae171be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can obtain the frequency of given word in either spam comments or ham comments easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b6590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaec13e9bf353681265bbe608e2ef6da",
     "grade": false,
     "grade_id": "cell-6c01d244cd2d1996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Frequency of the word \"love\" in the spam comments: {spam_word_frequencies[\"love\"]}')\n",
    "print(f'Frequency of the word \"love\" in the ham comments\": {ham_word_frequencies[\"love\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100d80c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f3024d7c3dff5dbde07d70a545285fe",
     "grade": false,
     "grade_id": "cell-e1d9172426f60881",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the frequencies we can now estimate the likelihoods $P(W_i|S = 1)$ and $P(W_i|S = 0)$ based on the training data.\n",
    "\n",
    "If a word is not present in the training data of either spam or ham comments, we simply ignore the word. More sophisticated strategies also exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214b404",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2314cf1e065cd1e510ff25dd0e279258",
     "grade": false,
     "grade_id": "cell-52b64ce4b8929cba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.9\n",
    "\n",
    "- Complete the functions `likelihood_spam` and `likelihood_ham`.\n",
    " - `likelihood_spam` that should return the estimated probability of a word given that the word is in a spam comment. The word can be assumed to be sampled randomly from all the spam words.\n",
    " -  `likelihood_ham` that should return the estimated probability of a word given that the word is in a ham comment. The word can be assumed to be sampled randomly from all the ham words.\n",
    "\n",
    "The case for word not being present in either of the classes is already dealt with in the implementations. In that case we simply return $1$ as that way the term will cancel out in the final posterior computation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6c8f8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bdefb49eba08e45ece3bde0cdd8daa6",
     "grade": false,
     "grade_id": "cell-a1269efaca927107",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def likelihood_spam(word): \n",
    "    '''\n",
    "    Parameter:\n",
    "    word -- The word for which the likelihood is to be calculated\n",
    "\n",
    "    Returns:\n",
    "    Likelihood of the word given that the word is in a spam comment, should return\n",
    "    1 if the word is not present in either spam or ham training data\n",
    "    '''\n",
    "    # If the word is present in both of the classes\n",
    "    if word in spam_word_frequencies and word in ham_word_frequencies:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    return 1\n",
    "\n",
    "def likelihood_ham(word):\n",
    "    '''\n",
    "    Parameter:\n",
    "    word -- The word for which the likelihood is to be calculated\n",
    "\n",
    "    Returns:\n",
    "    Likelihood of the word given that the word is in a ham comment, should return\n",
    "    1 if the word is not present in either spam or ham training data\n",
    "    '''\n",
    "    if word in spam_word_frequencies and word in ham_word_frequencies:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89f7a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe24949eaa917ea392557833ad972353",
     "grade": true,
     "grade_id": "cell-50ea69d61f4d2454",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n",
    "\n",
    "np_testing.assert_almost_equal(likelihood_spam('part'), 0.000363735564244794)\n",
    "np_testing.assert_almost_equal(likelihood_ham('part'), 0.0016826518593303045)\n",
    "np_testing.assert_equal(likelihood_spam('non-existant-word'), 1.0)\n",
    "np_testing.assert_equal(likelihood_ham('non-existant-word'), 1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60335f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9d0208a38bb58be4986a7cd478f2d01",
     "grade": true,
     "grade_id": "cell-d9c3c05e7ae36c9a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6867dce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c0fed8370eb9a51d3aa8a30a88e9afe",
     "grade": false,
     "grade_id": "cell-7410bf59b075a3fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the implemented functions we can now compute the final posterior probability $P(S=1|w_1 \\in W, \\dots, w_n \\in W)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90de960",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5adae4e6b99c296c01f73a5e8317692",
     "grade": false,
     "grade_id": "cell-5c7178dce0ac4119",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A4.10\n",
    "\n",
    "- Complete the function `posterior_spam` that should return the estimated posteror probability of a comment being spam.\n",
    "    \n",
    "The comment should first be forced into lower case and only unique alphanumeric words should be extracted. Note that the part doing that is already implemented.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0feba",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9269861f6361a392a510cbdd68ab7189",
     "grade": false,
     "grade_id": "cell-57dbfa15983d6900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def posterior_spam(comment):\n",
    "    '''\n",
    "    Parameter:\n",
    "    comment -- String containing the comment for which the posterior probability is to be calculated\n",
    "\n",
    "    Returns:\n",
    "    Posterior probability of the comment being spam\n",
    "    '''\n",
    "\n",
    "    # Comment is forced into lower case and only unique alphanumeric words are extracted.\n",
    "    words = findall(\"[a-z0-9äö']+\", comment.lower())\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859c0c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b97ee8ff6a75924855398d050dc55c32",
     "grade": true,
     "grade_id": "cell-4ce3e36d897817fc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n",
    "\n",
    "np_testing.assert_almost_equal(\n",
    "    posterior_spam('This is a test sentence'),\n",
    "    0.079718869600925)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158119a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cb348ad94efd8ecdc0a4d13412f9337",
     "grade": true,
     "grade_id": "cell-834d49953ea5cbed",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5c239",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae45a25158202bc8be6cc59fbf558905",
     "grade": false,
     "grade_id": "cell-fd785bfcbf1e5d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can test our classification algorithm. We classify a comment as spam if the posterior spam probability is larger than $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df6cb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b998c799d7487ae2bedf9190941f4375",
     "grade": false,
     "grade_id": "cell-5f80f16513219dcb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.array([posterior_spam(comment) for comment in testing_comments['CONTENT']])\n",
    "discretized_predictions = predictions > 0.5\n",
    "\n",
    "labels = testing_comments['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582aad5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62ae803e95ec45e1fab095fb10dc1fce",
     "grade": false,
     "grade_id": "cell-fcc293047d1cda9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = np.sum(discretized_predictions == labels) / len(testing_comments)\n",
    "\n",
    "print(f\"Classification accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5d4f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ae6145953f7ee3be7f5a637e22a2a3a",
     "grade": false,
     "grade_id": "cell-eafe63fe60b424d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If everything is implemented correctly, the classification accuracy should be approximately $0.93$. Let us still plot the confusion matrix for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a1dcf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "161ddb7b150d51a8b790c893ea66e96a",
     "grade": false,
     "grade_id": "cell-cdfbc60a188e5892",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix = calculate_confusion_matrix(labels, discretized_predictions)\n",
    "heatmap(\n",
    "    confusion_matrix.T,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cbar=False,\n",
    "    xticklabels=['ham', 'spam'],\n",
    "    yticklabels=['ham', 'spam']\n",
    ")\n",
    "plt.yticks(range(3))\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b2793-87af-40aa-b55d-33054291b3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
