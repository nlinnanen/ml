{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f347438",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6965303d5f49b96c0896e5ab244f7d4e",
     "grade": false,
     "grade_id": "cell-d8c0fc514422446a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "## Lectures 5 & 6 - Non-parametric methods and deep learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcc999-dab2-4ef2-9dd4-d5faee4f11fa",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Decision trees](#Decision-trees)\n",
    "2. [Artifical neural networks (ANN)](#Artifical-neural-networks-(ANN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67030154-f574-4349-9704-b5f212004353",
   "metadata": {},
   "source": [
    "# General Instructions\n",
    "- Jupyter notebook is supposed to be run cell by cell in order, please do not skip any code cell, this will cause some errors. Also running cells back and forth sometimes might also incur errors. If you feel you lost your track, you can click \"Kernel->Restart\" from the menu to restart the process.\n",
    "- Before submitting your assignment, ensure that it does not contain trivial errors by pressing the \"validate\" button at the top.\n",
    "- Your implementations are supposed to be added to the places where it reads \"YOUR CODE HERE\". Please also remove the \"raise NotImplementedError()\" line before submitting.\n",
    "- Please DO NOT change the metadata of any cell, cells for demo and instructions are not editable.\n",
    "- Please DO NOT change the order of solution cell and test cell, you will lost points if the order is changed.\n",
    "- You can copy lines of code from cells that are not editable, but please DO NOT copy and paste them as cells, this may incur validation error. \n",
    "- You can add extra cells or code to help double-check your solution, but please make sure that variables required by tasks are not overwritten, or just delete those extra cells before submitting.\n",
    "- Please DO NOT change file names in you submission, renamed files can not be recognized by the grading system.\n",
    "- Reading the documentation of Python libraries is always a good practice, all the Python libraries (Numpy, Pandas, Sklearn,etc.) we utilized in this course provide very well organized documentation for each method/class/function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857d6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T06:52:16.597034Z",
     "start_time": "2022-01-25T06:52:13.757048Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b84db88e668d8a3a987bf8f360e90ea1",
     "grade": false,
     "grade_id": "cell-ba12c5c47b74176a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable code auto-completion\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_text, plot_tree, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures   \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105e5bf-18c0-419a-8bc8-0dd519f80399",
   "metadata": {},
   "source": [
    "# Decision trees\n",
    "\n",
    "### Learning goals\n",
    "- To train and fit a decision tree classifier\n",
    "- To be able to assess the accuracy of a decision tree\n",
    "- To interpret a decision tree\n",
    "\n",
    "A decision tree is a non-parametric method used in classification and regression tasks. In this exercise, you will train a decision tree classifier to assess the edibility of mushrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fca93e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb48d3c71ce2a48993d86efa2c2f2638",
     "grade": false,
     "grade_id": "cell-1aa5d80bc5076d91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "This dataset is from https://archive.ics.uci.edu/ml/datasets/Mushroom. From the data description: \"*This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one.*\"\n",
    "\n",
    "For convenience, the original data has been modified to accomodate more human-readable categories and features and saved as `mushroom_data.csv`.\n",
    "\n",
    "Your goal is to build a classifier for these mushroom species, with edibility as a label. Is it possible to tell apart poisonous mushrooms from edible ones based on the data?\n",
    "\n",
    "First, let's store the data into a pandas `DataFrame` and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02e07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T06:52:16.634919Z",
     "start_time": "2022-01-25T06:52:16.599288Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a821558ca6e28ea07e246dc4f9d20088",
     "grade": false,
     "grade_id": "cell-60a7f3a9ad13dae2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mushroom_data.csv\") # read the data\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435b8be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7839627a002ae63725f6f05fd594bbc",
     "grade": false,
     "grade_id": "cell-c8a753eada83fc7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualization\n",
    "\n",
    "Next, we can visualize the data. For count data, a barplot would be a good starting point. Here, we are using the `seaborn` library's [countplot()](https://seaborn.pydata.org/generated/seaborn.countplot.html) function. We can see that the labels are quite evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01db2ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T06:52:16.675912Z",
     "start_time": "2022-01-25T06:52:16.641138Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf329d9c5653747bab3ed9d715cf919c",
     "grade": false,
     "grade_id": "cell-c99db19d6650a759",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the label\n",
    "sns.countplot(x = \"y\", data = data)\n",
    "plt.title(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Choose some features to visualize\n",
    "sns.countplot(x = \"gill-color\", data = data, hue = \"y\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Gill color\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x = \"odor\", data = data, hue = \"y\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Odor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a748c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37d00152f95aef61a914c90d669b1a56",
     "grade": false,
     "grade_id": "cell-3481f31ecaf3ec6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fitting the classifier\n",
    "\n",
    "We will use sklearn's DecisionTreeClassifier to construct a decision tree from our data. Check scikit-learn's tutorial on [Decision Trees](https://scikit-learn.org/stable/modules/tree.html) for additional information and inspiration for your future projects.\n",
    "\n",
    "First, extract features $X$ and labels $y$ from the data and encode edibility (label $y$) of the mushroom $i$ as $y_i \\in \\{0,1\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586cda9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c0ad474726c42a13e6da3cb08dea8a0",
     "grade": false,
     "grade_id": "cell-fd411858b74fcec4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.where(data['y'] == \"edible\", 1, 0) # encode edibility as 1 or 0\n",
    "\n",
    "X = data[data.columns]\n",
    "X = X.drop(columns = [\"y\"]) # drop the label\n",
    "\n",
    "y # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d11dc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3b9fb9d1326aa5827b80a316e3e36d8",
     "grade": false,
     "grade_id": "cell-16a56fdb76aab147",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then, we need to encode the categorical variables: DecisionTreeClassifier cannot handle categorical features unless they are binary. For this, we use [one-hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "In short, one-hot encoding takes a categorical feature/variable and changes it into 0s and 1s - even if the feature has more than two unique categories. For example, if feature $a$ (let's say, mushroom cap color) has observations belonging in categories $a \\in \\{yellow, pink, blue\\}$, we could encode these as features $a_{yellow}, a_{pink}, a_{blue}$. An observation $i$ is now associated with these three features, and will have a value of 1, if the observation is of that group and 0 for others. Below, we have an example data set of four observations before and after one-hot encoding:\n",
    "\n",
    "Before one-hot encoding:\n",
    "$$\\mathbf{a} = \\begin{bmatrix}\"yellow\"\\\\\"pink\"\\\\\"blue\"\\\\\"blue\"\\end{bmatrix}$$\n",
    "\n",
    "After one-hot encoding:\n",
    "$$\\mathbf{a}_{yellow} = \\begin{bmatrix} 1\\\\ 0\\\\0\\\\0\\end{bmatrix}, \\mathbf{a}_{pink} = \\begin{bmatrix} 0\\\\ 1\\\\0\\\\0\\end{bmatrix}, \\mathbf{a}_{blue} = \\begin{bmatrix} 0\\\\ 0\\\\1\\\\1\\end{bmatrix}$$\n",
    "    \n",
    "\n",
    "\n",
    "As you can see, this increases the number of features in the data, but will allow us to work with only ones and zeros. This in turn makes it possible to for example plot a heatmap - and use DecisionTreeClassifier, which only supports continous or binary variables.\n",
    "\n",
    "\n",
    "Here, we are using pandas function [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) for one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce00dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "318d5496e50cd98c4383494bbef30878",
     "grade": false,
     "grade_id": "cell-e7f9112d6a7ceda2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, dtype = int)\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128bb8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1123ab1c418753eb56427806ab88c82",
     "grade": false,
     "grade_id": "cell-a33865730c990fbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We would also like to know how well our classifier performs on unseen data - could we actually use our classifier to predict edibility of a mushroom we found in the woods? For this, we will divide our data into training and test sets. The training set will be used to train our classifier, and we'll test its predictive ability on the test set, which will act as our approximation of new data. [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) function from scikit-learn can be used to easily perform the split to train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cd19a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cf19ea4175a4043dde2d32baf0f8dd8",
     "grade": false,
     "grade_id": "cell-88a97df4bf1b4ea6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d42963",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0884618c49e1bd40c232c930d734e6a9",
     "grade": false,
     "grade_id": "cell-57b20f00053e48af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.1\n",
    "\n",
    "Now we can fit the decision tree classifier. Your task is to use [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) from scikit-learn. **Set random_state = 0 and max_depth = 2.**\n",
    "\n",
    "1. Fit a decision tree classifier\n",
    "    - As before in classification/regression assignments:\n",
    "        1. Create a classifier object\n",
    "        2. Call the fit method\n",
    "        3. Call the predict method\n",
    "    \n",
    "    \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9734b9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b98879b9cec4f72a4cf369cbc3700579",
     "grade": false,
     "grade_id": "cell-99707d0dfd8bc9d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and train the DecisionTreeClassifier() using the training data. Predict on the test set. \n",
    "# Set random_state = 0.\n",
    "\n",
    "# clf = ...  # train using the train data\n",
    "# clf ...    # fit the classifier\n",
    "# y_pred = ... # predict for test data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "## sanity check\n",
    "assert isinstance(clf, DecisionTreeClassifier), \"please initialise a DecisionTree classifier\"\n",
    "assert len(y_pred) == len(y_test), \"the length of y_pred is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa5a5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e852c370a508fed6f1b93260b76628ae",
     "grade": true,
     "grade_id": "cell-b9acd559043368d3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb9727",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05b59478d3c4ef5d3e28f62915d1f0c2",
     "grade": false,
     "grade_id": "cell-0a2bdfb6cd6346b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.2\n",
    "\n",
    "Hint: relevant sklearn functions have been imported for you.\n",
    "    \n",
    "1. Compute the accuracy of the classifier\n",
    "2. Create the confusion matrix.\n",
    "    \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e992b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d012a5919cb4841c25c6574971d05c8f",
     "grade": false,
     "grade_id": "cell-27266e380c08a3b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the accuracy of the predicted classes & the confusion matrix\n",
    "\n",
    "# acc = ...\n",
    "# confmat = ...\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# plot the confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(confmat,annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels',fontsize=15)\n",
    "ax.set_ylabel('True labels',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3324a2c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff932cd584499d8aeaad8b54b779cadc",
     "grade": true,
     "grade_id": "cell-5978388181afbe0c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d8801",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8171f5c1e384f3ce9df3845b97d5c49",
     "grade": true,
     "grade_id": "cell-5978388181afbe0ct",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is for tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e3040",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "259ff0e2ca2f1c1066215cb4fa2cae3e",
     "grade": false,
     "grade_id": "cell-1f45c4b1c89d7a5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see that the accuracy of the classifier is high. This could indicate that our data is \"good\" in the sense that it is easily separable. It could also be a symptom of overfitting. To alleviate the effect of overfitting, we could for example use ensemble methods such as random forests (see lecture slides for details).\n",
    "\n",
    "Finally, we can plot the decision tree. The tree is also saved as a pdf `mushroom_tree.pdf` for a higher resolution image. Take a look at the tree and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f897bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "106023683b6ce1bbe565e52766861d4b",
     "grade": false,
     "grade_id": "cell-74b02274a0b0a79f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_tree(clf, feature_names = list(X.columns),  filled = True, class_names=[\"poisonous\", \"edible\"])\n",
    "plt.show()\n",
    "\n",
    "# save as pdf for a high res image:\n",
    "import pydotplus\n",
    "d_tree = export_graphviz(clf, feature_names = list(X.columns), filled = True, class_names=[\"poisonous\", \"edible\"])\n",
    "pydot_graph = pydotplus.graph_from_dot_data(d_tree)\n",
    "pydot_graph.write_pdf('mushroom_tree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9e4e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80c2444804230885ec7eab5bed4369d5",
     "grade": false,
     "grade_id": "cell-8206a1525c7e01cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.3\n",
    "\n",
    "**Q1:** You are stranded in a forest, starving and spot a mushroom nearby. Upon closer inspection, you find that it smells and its stalk is shaped like a club. Based on our decision tree that you happen to have with you, is the mushroom poisonous (Q1 = 0) or edible (Q1 = 1)? Explore the `mushroom_tree.pdf` file or the plotted decision tree to find the answer.\n",
    "    \n",
    "    \n",
    "**Q2:** In the case of classifying mushrooms based on edibility, which would be worse, a false positive (Q2 = 0) or false negative (Q2 = 1) result?\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff08d0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc802885d1540f379fb1c654c4ac9c0e",
     "grade": false,
     "grade_id": "cell-82f542b8f824eab4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# choose the correct answer\n",
    "\n",
    "#Q1 = ...\n",
    "#Q2 = ...\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5c033",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8eed9939653c0eba7dd7e5bcbec98826",
     "grade": true,
     "grade_id": "cell-95cab628a672a762",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418f1bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cb22c0f342dfa152ee747613335a2dd",
     "grade": true,
     "grade_id": "cell-ac39097ad275fe27",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30feac88",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5a9292748f5104a837f873f257a4831",
     "grade": false,
     "grade_id": "cell-d00586aa66fd4d56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "A word of warning: you shouldn't actually eat mushrooms you do not know even if you have a cool decision tree of high accuracy with you. You should only pick edible mushrooms that you are absolutely certain about, preferably taught to you by an expert - so always check before picking!\n",
    "\n",
    "Possible problems with the decision tree are:\n",
    "- **Overfitting:** High accuracy could be a symptom of overfitting (the model \"memorizes\" the data and will perform poorly on samples outside the data).\n",
    "- **External validation:** We didn't do any external validation for the model - there are no samples outside of this particular dataset to test the accuracy of our classifier on out-of-distribution samples.\n",
    "- **Data limitations:** The data only considers mushrooms of two families (Agaricus and Lepiota) in North America - naturally the classifier likely doesn't yield correct results for mushrooms of other families or from different geographical locations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3724c0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60e0c08177de44cae716a90bee25f3ec",
     "grade": false,
     "grade_id": "cell-d4e7e93e24ec4d65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " # Artifical neural networks (ANN)\n",
    " \n",
    " Being a subset of machine learning (ML) methods, **deep learning** follows the basic ML principle: find a hypothesis map out of a hypothesis space (represented by neural networks) that minimizes a chosen loss on datapoints. \n",
    "\n",
    "Neural networks are called networks because they are typically represened by composing together many different functions, and the computed values create a network-like structure. For example, we might have three functions $f^{(1)},f^{(2)}$and $f^{(3)}$ connected in a chain, to form $f(x)=f^{(3)}(f^{(2)}(f^{(1)}))$. In this case, $f{(1)}$is called the first layer of the network, $f^{(2)}$ is called the second layer, and so on. The overall length of the chain gives the depth of the network. Networks with multiple layers are called deep networks, hence the name deep learning.\n",
    "\n",
    "Typically the final layer is called the **output layer**, and represents the label that we want to predict. The training datapoints \"tell\" what the output layer must do at each datapoint - it should produce a value that is close to the desired label. The behaviour of other layers however, is not directly specified by the training data. Instead the learning algorithm decides how to use these layers to find the best approximation of the ideal map by minimizing (locally) the loss on the training dataset. Thus, these layers are called **hidden layers**. \n",
    "<img src=\"neural_network.png\" alt=\"neural network\" style=\"width:600px;height:350px;\">\n",
    "\n",
    "In this assignment a fully connected multi-layer neural network, also called feed-forward neural network or **Multilayer Perceptron (MLP)**, is used to represent a hypothesis space that includes highly non-linear functions. MLP is the simplest type of a neural network, where each cell (neuron) is 'connected' to all the cells from the next layer, and only the next layer uses its value.\n",
    "\n",
    "If you wish to gain understanding of how a neural network actually works and learns, [this video series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) by 3blue1brown provides a briliant visual explanation.\n",
    "\n",
    "## Learning goals\n",
    "After successfully completing this assignment, you should be able to:\n",
    "* understand the difference of hypothesis maps between MLP and linear models\n",
    "* understand that activation functions are a key part of neural network design\n",
    "* train MLPs to complete a regression task\n",
    "* train MLPs to complete a classification task\n",
    "* have some basic understanding of gradient based learning of ANN weights\n",
    "* use grid-search for adjusting multiple MLP hyper-parameters such as number of layers and learning rate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8c53b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f75c09ee21374df898ac9e1d1dba4483",
     "grade": false,
     "grade_id": "cell-234415d84fdd72a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Basic neural network structure\n",
    "\n",
    "Take a look at the image below, showing a very basic neural network, with one-element input layer `x` and output layer `y`, and a single hidden layer with 3 hidden units:\n",
    "\n",
    "![A simple neural network schema](network-schema.png)\n",
    "\n",
    "\n",
    "The process of calculating the output of the network is as follows. We have the network defined as above, and a bias vector `[bias1, bias2, bias3]` corresponding to the `hidden1, hidden2, hidden3` hidden units. Then:\n",
    "1. We multiply x with the first layer's weights, and add a constant bias term. We have obtained initial values of the hidden 'neuron' activations. A single value is calculated as:\n",
    "$$\n",
    "hidden_i = x * weight_{1i} + bias_i\n",
    "$$\n",
    "1. Simply multiplying and adding to the initial value of x would not let us represent any complex non-linear functions, so we need to introduce a non-linearity to our network. It is done via activation functions in the hidden layer, and the most common one is the rectified linear unit (ReLU):\n",
    "$$\n",
    "ReLU(x) = max(x, 0)\n",
    "$$\n",
    "It could be thought of as a function replacing negative values with 0s. We apply it to our hidden layer activations:\n",
    "$$\n",
    "hidden_i = ReLU(hidden_i)\n",
    "$$\n",
    "1. Now that we have the activation values, we multiply them with the final weights and sum the result together to obtain the final output:\n",
    "$$\n",
    "y = hidden_1 * weight_{21} + hidden_2 * weight_{22} + hidden_3 * weight_{23}\n",
    "$$\n",
    "\n",
    "Note that there is no bias in the last step. We also do not use ReLU anymore, as it is a simple regression network. However, for classification, you would use a different activation function for your output to turn it into a probability distribution - see [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) (binary) or [softmax](https://en.wikipedia.org/wiki/Softmax_function) (multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27311f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a87692f01e664dd8a227657494a3166",
     "grade": false,
     "grade_id": "cell-e9e08ef6beabd599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A3.4\n",
    "    \n",
    "Use your understanding of how a neural network works, to set the correct weights and biases for our toy neural network example from above, so that the resulting function `f(x) = y` is a non-linear function looking like this:\n",
    "![Neural Network hypothesis plot](network-triangle.png)\n",
    "    \n",
    "Note that this would not be possible with linear models we studied previously, such as linear regression or SVMs.\n",
    "\n",
    "The vertices of the triangle must be the points `(0, 0), (1, 1), (2, 0)`. Fill in any missing (`None`) values in the `weights_1`, `weights_2`, or `bias` vectors. There is no need to change the values that have already been set!\n",
    "    \n",
    "Hint:  Try it out as a math problem with pen and paper if you have trouble! Try to think what are the already given functions $hidden_1(x)$ and $hidden_3(x)$, what unknowns there are in $hidden_2$, and what is the result of adding them together to obtain $y = f(x) = hidden_1(x) + hidden_2(x) + hidden_3(X)$ - e.g. with the given values:\n",
    "    \n",
    "$\n",
    "hidden_3(x) = 1 * x - 2 \n",
    "$; for `x > 2`(i.e.`(1*x-2) > 0`)\n",
    "    \n",
    "$\n",
    "hidden_3(x) = 0\n",
    "$; otherwise\n",
    "    \n",
    "There are also visualizations of the intermediate plots below.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a5f1d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23830d414937472cfd82e727bb77e038",
     "grade": false,
     "grade_id": "cell-7670bbe6fa0c3bce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## In the following two lines of code, please fill in the None values in a way allowing you to obtain \n",
    "## the given hyphothesis shape.  No need to change the given values in weights_1, bias.\n",
    "\n",
    "weights_1 = np.array([1., None, 1.])     # a vector represents [w11, w12, w13]\n",
    "bias = np.array([0., None, -2.])         # a vector represents [bias1, bias2, bias3]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "weights_2 = np.array([1, -1, 1])         # a vector represents [w21, w22, w23]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4c47d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70cb55bf22a652d2db73864b6c0539c4",
     "grade": false,
     "grade_id": "cell-4660935964167f48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hidden(x, weights_1, bias):\n",
    "    \"\"\"\n",
    "    Inputs: x,feature,scalar\n",
    "            weights_1, vector, [w11,w12,w13]\n",
    "            bias, vector, [bias1,bias2,bias3]\n",
    "    Output: activations, vector\n",
    "    \"\"\"\n",
    "    hidden_x = x * weights_1 + bias \n",
    "    return np.maximum(hidden_x, 0) # Apply the ReLU activation\n",
    "\n",
    "def network(x, weights_1, bias, weights_2):\n",
    "    \"\"\"\n",
    "    Inputs: x, feature,scalar\n",
    "            weights_1, vector, [w11,w12,w13]\n",
    "            bias, vector, [bias1,bias2,bias3]\n",
    "            weights_2, vector, [w21,w22,w23]\n",
    "    Output: predicted label, scalar\n",
    "    \"\"\"\n",
    "    hidden_x = hidden(x, weights_1, bias) # Calculate the hidden activations\n",
    "    final_x = hidden_x * weights_2 # Multiply them with the final weights [w21, w22, w23]\n",
    "    return sum(final_x) # Sum the result to obtain the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c7427",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3069943951f8b4f99eda55f7ad2938",
     "grade": false,
     "grade_id": "cell-319e3dcf744c54ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_to_plot = np.linspace(-0.5, 2.5, 99) # X values to serve as inputs for our network for plotting\n",
    "plt.figure(figsize=(10, 12))\n",
    "for i in range(3):\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    \n",
    "    # Compute the hidden layer activations\n",
    "    hidden_to_plot = [hidden(x, weights_1, bias)[i] for x in x_to_plot]\n",
    "    \n",
    "    # Make sure all plots use the same scale\n",
    "    plt.xlim(-0.5, 2.5) \n",
    "    plt.ylim(-0.5, 1.5)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # Plot the hidden layer activations\n",
    "    plt.title(f'Hidden {i + 1} plot')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f'h{i + 1}')\n",
    "    plt.plot(x_to_plot, hidden_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dad6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de2581b39475a341160759a41733c6db",
     "grade": false,
     "grade_id": "cell-88dc8950d3e45bbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_to_plot = [network(x, weights_1, bias, weights_2) for x in x_to_plot] # Use our network to obtain y values\n",
    "plt.title('Neural Network toy example hyphothesis function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "_ = plt.plot(x_to_plot, y_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c2aaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe9e05a786748e7eb8607307a6a298ea",
     "grade": false,
     "grade_id": "cell-466b8b0fe65a0a13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check the resulting values:\n",
    "assert np.isclose(network(0, weights_1, bias, weights_2), 0.)\n",
    "assert np.isclose(network(1, weights_1, bias, weights_2), 1.)\n",
    "assert np.isclose(network(2, weights_1, bias, weights_2), 0.)\n",
    "assert np.isclose(y_to_plot[0], 0.)\n",
    "assert np.isclose(y_to_plot[-1], 0.)\n",
    "assert np.isclose(y_to_plot[len(y_to_plot) // 2], 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a6ca7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d832ffbdc6f0dbb8e3171d077e33003",
     "grade": true,
     "grade_id": "cell-e82a2c54e7f11554",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests, leave it as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1e788",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fc1d7bbbb3cb5310bb7fcdfcd33d277",
     "grade": false,
     "grade_id": "cell-ffbb315f8c5c2c79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data stored in the file 'FMIData_Assignment7.csv' and clean the dataset\n",
    "data = pd.read_csv('FMIData_Assignment7.csv')\n",
    "# drop unrelevant columns\n",
    "data.drop(columns=['Time zone','Precipitation amount (mm)','Snow depth (cm)',\\\n",
    "                 'Ground minimum temperature (degC)','Maximum temperature (degC)', 'Minimum temperature (degC)'],inplace=True)  \n",
    "data.columns =['year','m','d','time','air temperature'] # rename columns \n",
    "\n",
    "# Select only weather recordings whose property 'time' is equal to `00:00`\n",
    "data = data[data['time'] == '00:00']\n",
    "\n",
    "# Shift the column 'air temperatrue' by different periods to obtain history records\n",
    "data['pre_1'] = data['air temperature'].shift(1)\n",
    "data['pre_2'] = data['air temperature'].shift(2)\n",
    "data['pre_3'] = data['air temperature'].shift(3)\n",
    "data['pre_4'] = data['air temperature'].shift(4)\n",
    "data['pre_5'] = data['air temperature'].shift(5)\n",
    "\n",
    "data = data.iloc[5:] # drop the first 5 rows which involves NAN\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d06e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5904fdd6636cab0d02b7fe19cc3df38f",
     "grade": false,
     "grade_id": "cell-1da7a2e0528ef0fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "## Student Task A3.5\n",
    "\n",
    "In this problem formulation, a datapoint represents a day corresponding to a row in the dataframe. The column \"air temperature\" stores the labels and columns 'pre_1', 'pre_2', 'pre_3', 'pre_4', 'pre_5' are used as features.\n",
    "    \n",
    "Before training an MLP, let's firstly try out the old method we used before: PolynomialRegression. \n",
    "    \n",
    "As usual, we create the feature matrix and label vector and then train several models with different polynomial degrees to see which one is ideal.\n",
    "\n",
    "**Your task** is: create a feature matrix and a label vector\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92494b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bc85e7e49230a24b43bd4673e858106",
     "grade": false,
     "grade_id": "cell-31ed31bc9f68a7d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Create feature matrix and label vector:\n",
    "# X = ...      # features are air temperatures of previous 5 days \n",
    "# y = ...      # label is air temperature of the present day\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(X)\n",
    "print(y.shape)\n",
    "\n",
    "assert X.ndim == 2,  \"Wrong dimension of X\"  #sanity check the dimension of X\n",
    "assert X.shape[1] == 5, \"wrong shape of X\"  #sanity check the shape of X\n",
    "assert y.ndim == 1,  \"Wrong dimension of y\"  #sanity check the dimension of y\n",
    "assert y.shape[0] == 708, \"Wrong shape of y\" #sanity check the shape of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd9d51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5a368e2e0764db73ebfdd1fbcf9b2b1",
     "grade": true,
     "grade_id": "cell-bf26bc22e8a38ca5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the test cell, leave it as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0875348",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2f1a1bb03d7d7c9e6618ab984568c8f",
     "grade": false,
     "grade_id": "cell-f300e709bd4c8168",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val,  y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d7351",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a14a268e01426deb9af465b253faa25",
     "grade": false,
     "grade_id": "cell-ff4a0b04a764dfd3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape[1] == 5, \"Incorrect shape for X_train\"\n",
    "\n",
    "## define a list of values for the maximum polynomial degree \n",
    "degrees = [1,2,3,4]    \n",
    "\n",
    "# we will use this variables to store the resulting training and validation errors for each polynomial degree\n",
    "linear_tr_errors = []          \n",
    "linear_val_errors = []\n",
    "for degree in degrees:    # use for-loop to fit polynomial regression models with different degrees\n",
    "    lin_regr = LinearRegression(fit_intercept=False) # NOTE: \"fit_intercept=False\" as we already have a constant iterm in the new feature X_poly\n",
    "    poly = PolynomialFeatures(degree=degree)    # generate polynomial features\n",
    "    X_train_poly = poly.fit_transform(X_train)    # fit the raw features\n",
    "    lin_regr.fit(X_train_poly, y_train)    # apply linear regression to these new features and labels\n",
    "  \n",
    "    y_pred_train = lin_regr.predict(X_train_poly)    # predict using the linear model\n",
    "    tr_error = mean_squared_error(y_train, y_pred_train)    # calculate the training error\n",
    "    X_val_poly = poly.transform(X_val) # transform the raw features for the validation data \n",
    "    y_pred_val = lin_regr.predict(X_val_poly) # predict values for the validation data using the linear model \n",
    "    val_error = mean_squared_error(y_val, y_pred_val) # calculate the validation error\n",
    " \n",
    "    linear_tr_errors.append(tr_error)\n",
    "    linear_val_errors.append(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75927125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a2a78dd1a5c2c8de357dcb5770556b7",
     "grade": false,
     "grade_id": "cell-997c4775de604cca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a table to compare training and validation errors\n",
    "errors = {\"poly degree\":degrees,\n",
    "          \"linear_train_errors\":linear_tr_errors,\n",
    "          \"linear_val_errors\":linear_val_errors,\n",
    "         }\n",
    "pd.DataFrame({ key:pd.Series(value) for key, value in errors.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe489ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d1cf2f818986d9dbe12653e5dbe42a7",
     "grade": false,
     "grade_id": "cell-c5ac0ab11312ac41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.6\n",
    "\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: Which of the models from A3.5 would you recommend based on the above table?\n",
    "- Answer 1: Degree 1\n",
    "- Answer 2: Degree 2\n",
    "- Answer 3: Degree 3\n",
    "- Answer 4: Degree 4\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67972f5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0d56b6e1f3a35e2b6ba001be8153611",
     "grade": false,
     "grade_id": "cell-1a316f986d4ce92c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "# Answer_Q1  = ...  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "print(\"my answer is: \", Answer_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d070b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32d146ea74f9f52757e0ce893e877221",
     "grade": false,
     "grade_id": "cell-da87dcb975c6080d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check datatype of Answer_Q1\n",
    "assert Answer_Q1 in (1, 2, 3, 4), \"Please answer with a number from 1 to 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4793c03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0efef0b56334b119ac43bebd92f41719",
     "grade": true,
     "grade_id": "cell-6476786fc985c1c6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests, leave it as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a2074",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8897b6e1000f8eaa68e6ef4bfa4a399",
     "grade": false,
     "grade_id": "cell-9572f2d6ae91869a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.7\n",
    "\n",
    "Now, we know the performance of polynomial regression on this prediction task. It is time to try out MLP and see whether MLP can defeat polynomial regression or not.\n",
    "\n",
    "We will still focus on Sklearn library and use Sklearn class [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) to implement our model, but for complicated modern deep learning tasks, Python provides other easy-to-use libraries for the design and training of ANN, such as [Keras](https://keras.io/).\n",
    "\n",
    "\n",
    "**Hypothesis Space used in this task - MLP Structure:**\n",
    "- one input layer consists of the individual features (5 features) and is the entry point to the MLP.\n",
    "- several hidden layers with 15 neuron units in each layer and [ReLU activation function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)), we will explore the number of hidden layers in this task, find out the ideal number of hidden layers for this given ML problem.\n",
    "\n",
    "- one final output layer with 1 neuron unit.\n",
    "\n",
    "For regularization strength and learning rate, default values are used.\n",
    "\n",
    "**Loss used in this task**: MSE\n",
    "\n",
    "In the following solution cell, you will:\n",
    "- Initialise an MLPRegressor, please use the `hidden_layer_sizes` defined for you and set `max_iter` to 1000, `random_state` to 42.\n",
    "- Train the regressor on the training set.\n",
    "- Evaluate the regressor on the training set and validation set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af1e56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f347e4462bf28e3c78b10412a4b395f",
     "grade": false,
     "grade_id": "cell-19b7106fad98c4cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "## define a list of values for the number of hidden layers\n",
    "num_layers = [1,2,4,6,8,10]    # number of hidden layers\n",
    "num_neurons = 15  # number of neurons in each layer\n",
    "\n",
    "\n",
    "# we will use this variable to store the resulting training errors corresponding to different hidden-layer numbers\n",
    "mlp_tr_errors = []          \n",
    "mlp_val_errors = []\n",
    "\n",
    "for i, num in enumerate(num_layers):\n",
    "    hidden_layer_sizes = tuple([num_neurons]*num) # size (num of neurons) of each layer stacked in a tuple\n",
    "    \n",
    "    # mlp_regr = ... # Initialise an MLPRegressor\n",
    " \n",
    "    # mlp_regr.fit(...,...)    # Train MLP on the training set\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ## evaluate the trained MLP on both training set and validation set\n",
    "    y_pred_train = mlp_regr.predict(X_train)    # predict on the training set\n",
    "    tr_error = mean_squared_error(y_train, y_pred_train)    # calculate the training error\n",
    "    y_pred_val = mlp_regr.predict(X_val) # predict values for the validation data \n",
    "    val_error = mean_squared_error(y_val, y_pred_val) # calculate the validation error\n",
    "    \n",
    "    # sanity check num of layers\n",
    "    assert mlp_regr.n_layers_ == num_layers[i]+2 # total layers = num of hidden layers + input layer + output layer\n",
    "    # sanity check the error values\n",
    "    assert 3 < tr_error < 4 and 5 < val_error < 6\n",
    "    \n",
    "    mlp_tr_errors.append(tr_error)\n",
    "    mlp_val_errors.append(val_error)\n",
    "\n",
    "# sanity check the length of array mlp_tr_errors\n",
    "assert len(mlp_tr_errors) == len(mlp_val_errors) == len(num_layers)\n",
    "print(mlp_tr_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c404625",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1b90a89e58e950e89b90203d76e74a1",
     "grade": true,
     "grade_id": "cell-e821099691a5fd27",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests, leave it as it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6f7ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "063dbe1438a9748be3946246f49d3948",
     "grade": false,
     "grade_id": "cell-65c50ddbb947082c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(num_layers, mlp_tr_errors, label = 'Train')\n",
    "plt.plot(num_layers, mlp_val_errors,label = 'Valid')\n",
    "plt.xticks(num_layers)\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cc3e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aa6099a7853846c8d1bdfd351fd3ced",
     "grade": false,
     "grade_id": "cell-cd740169ed6d99d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a table to compare the training and validation errors for MLPs with different number of hidden layers\n",
    "errors = {\"num_hidden_layers\":num_layers,\n",
    "          \"mlp_train_errors\":mlp_tr_errors,\n",
    "          \"mlp_val_errors\":mlp_val_errors,\n",
    "         }\n",
    "pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a7075",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a17c66aeb4bacf82c37b81404bf8c4ae",
     "grade": false,
     "grade_id": "cell-372c936508941969",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "## Student Task A3.8\n",
    "\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: Which of the models from A3.6 would you recommend based on the table above?\n",
    "- Answer 1: 1 hidden layer MLP\n",
    "- Answer 2: 2 hidden layers MLP\n",
    "- Answer 3: 4 hidden layers MLP\n",
    "- Answer 4: 6 hidden layers MLP\n",
    "- Answer 5: 8 hidden layers MLP\n",
    "- Answer 6: 10 hidden layers MLP \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc1128",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7761b664cf9b0b4f2bd17563ecf6a6b",
     "grade": false,
     "grade_id": "cell-3c2e8d4ba1cdcae7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "# Answer_Q1  = ...  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "print(f\"my answer is: Answer {Answer_Q1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e406d71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43179faa65b8435ae7c4f5c9592bcb57",
     "grade": false,
     "grade_id": "cell-b237fa26643c272b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check datatype of Answer_Q1\n",
    "assert Answer_Q1 in (1, 2, 3, 4, 5, 6), \"Please answer with a number 1-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d5c4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79a7311f6d585d5af4304b29c515a488",
     "grade": true,
     "grade_id": "cell-d467e30beb0c610b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests, leave it as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b33d77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d599161f6734fc4980bf07f42088f74",
     "grade": false,
     "grade_id": "cell-ad9cdc0ce8500e11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "l_errors = {\"poly degree\":degrees,\"linear_train_errors\":linear_tr_errors, \"linear_val_errors\":linear_val_errors,}\n",
    "print(\"training errors and validation errors of PolynomialRegression\")\n",
    "pd.DataFrame(l_errors).style.map(lambda x: \"background-color: yellow\" if x==np.max(linear_val_errors) else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524bcb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cb95bc909fd7d1ef45e6a2485cb9cb4",
     "grade": false,
     "grade_id": "cell-facd40ddb8c2f1c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m_errors = {\"mlp_train_errors\":mlp_tr_errors, \"mlp_val_errors\":mlp_val_errors}\n",
    "print(\"training errors and validation errors of MLP\")\n",
    "pd.DataFrame(errors).style.map(lambda x: \"background-color: yellow\" if x==np.max(mlp_val_errors) else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1f3a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1eb8c653ec750b88c44f8438ef14c353",
     "grade": false,
     "grade_id": "cell-72c134dcb16cc6b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PolynomialRegression vs MLP**\n",
    "\n",
    "The tables above compare the performance of PolynomialRegression and MLP on this specific ML problem. We can see that their performances are similar, but MLP is a bit better than PolynomialRegression. Considering sampling randomness, this suggests that deep learning methods are not always undisputed winners, particularly for simpler tasks where a simple model would train faster, predict quicker, and achieve comparable results.\n",
    "\n",
    "However, one significant advantage of MLP, even for simple problems, is that it is much less sensitive to model complexity than regression, so even without careful hyperparameter tuning the network always somehow 'does the job for us' with decent validation errors ~5, while regression explodes with an error of 18+ when we use a too complex model (max poly degree=4)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
